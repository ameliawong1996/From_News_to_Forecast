{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "\n",
    "from train_and_test import start_a_new_train, run_evaluation\n",
    "from AU_LF_dataload_final import parse_news_TS_final, train_validation_split\n",
    "from plot_comparision import plot_comparision\n",
    "from gpt_news_evaluation import validation_with_evaluation_agent,gpt_chain_of_thoughts\n",
    "from reselect_news import fetch_news,gpt_reselect_news,reselect_news_procedure\n",
    "from justify_news_format_final import justify_news_format_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial News Selection by Reasoning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = '''Please summerize the logic of selection of news that will change the regional electricity load consumption.'''\n",
    "\n",
    "format_output= ''' Predicting each state's region-level load consumption data in Australia with a time-frequency \n",
    "of 30 minutes per point involves understanding various factors. \n",
    "\n",
    "Positive Issues Leading to Increase in Load Consumption:\n",
    "\n",
    "Short-Term:\n",
    "1. Economic Growth: A surge in economic activity increases energy consumption.\n",
    "2. Technological Advancements: New power-requiring technologies can spike demand.\n",
    "3. Seasonal Factors: Extreme weather increases the use of air conditioning.\n",
    "4. Social Events: Large-scale events temporarily boost energy use.\n",
    "\n",
    "Long-Term:\n",
    "1. Population Growth: Leads to higher residential energy consumption.\n",
    "2. Industrial Development: Correlates with increased energy demands.\n",
    "3. Urbanization: Expansion of cities contributes to higher energy usage.\n",
    "4. Energy Transition: Shift towards electrically powered technologies.\n",
    "\n",
    "Negative Issues Leading to Decrease in Load Consumption:\n",
    "\n",
    "Short-Term:\n",
    "1. Economic Downturns: Lead to decreased industrial activity and lower energy consumption.\n",
    "2. Efficiency Improvements: Adoption of energy-efficient technologies reduces consumption.\n",
    "3. Weather Patterns: Mild weather can reduce heating and cooling needs.\n",
    "4. Public Health Crises: Can lead to reduced industrial and commercial activity.\n",
    "\n",
    "Long-Term:\n",
    "1. Energy Efficiency: Trends like better insulation and efficient appliances reduce consumption.\n",
    "2. Demographic Changes: Aging populations or declining birth rates can lead to decreased energy use.\n",
    "3. Policy and Regulation: Promote energy conservation and sustainability.\n",
    "4. Technological Innovations: Development of more efficient technologies.\n",
    "\n",
    "Other Factors:\n",
    "- Political Stability: Impacts energy policies and investments.\n",
    "- Global Market Dynamics: Affect local energy prices and consumption patterns.\n",
    "- Environmental Consciousness: Leads to changes in consumption behavior and renewable energy adoption.\n",
    "'''\n",
    "\n",
    "openai.api_base = #enter your api base \n",
    "openai.api_key = #enter your api key \n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-turbo-2024-04-09\", # or another model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant analyzing electricity load predictions.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt + format_output}\n",
    "    ]\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "with open('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/select_news_logic_iteration_0.txt', \"w\", encoding='utf-8') as file:\n",
    "    file.write(response[\"choices\"][0][\"message\"][\"content\"].replace(\"**\",\"\").replace(\"\\n\",\"\").replace(\"###\",\"\"))\n",
    "\n",
    "initial_reasoning = response[\"choices\"][0][\"message\"][\"content\"].replace(\"**\",\"\").replace(\"\\n\",\"\").replace(\"###\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic = \"Future Load Consumption\"\n",
    "prompt2 = f'''\n",
    "If I give you all news before the prediction, based on the above positive & negative issues analysis, \n",
    "1) please choose the news that may have a long-term affect on {topic};\n",
    "2) please choose the news that may have a short-term effect on today's  {topic}.  \n",
    "3) please choose the news that may have a real-time direct effect on today's  {topic}. \n",
    "If there is no suitable news, please say no. Also, please include the region (Australia/International/Others) and time information of these news. \n",
    "Organize the paragraph in this format: Long-Term Effect on Future {topic}: news is xxx; region is xxx; time is xxxx; the rationality is that xxx.\"\n",
    "'''\n",
    "\n",
    "format_output2=\"\"\"\n",
    "Remember to only give the json output including all relavant news and make it the valid json format.  Format is {\n",
    "\"Long-Term Effect on Future Load Consumption\": [\n",
    "        {\n",
    "            \"news\": \"Work on WA’s latest $1b lithium plant will start within days as US resources giant Albemarle begins building a major processing facility outside Bunbury, creating hundreds of jobs.\",\n",
    "            \"region\": \"WA\",\n",
    "            \"time\": \"2019-01-03 16:40:00\",\n",
    "            \"rationality\": \"The construction and operation of a major lithium processing facility will likely influence long-term electricity demand through increased industrial activity and potential population growth in the area due to new job opportunities.\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Another major renewable energy project was initiated in WA, expected to supply significant power by 2022.\",\n",
    "            \"region\": \"WA\",\n",
    "            \"time\": \"2019-03-15 11:30:00\",\n",
    "            \"rationality\": \"Long-term electricity load will be impacted by the integration of renewable energy sources, which are expected to offset dependence on traditional fossil fuels.\"\n",
    "        }\n",
    "    ],\n",
    "    \"Short-Term Effect on Today's Load Consumption\": [\n",
    "        {\n",
    "            \"news\": \"SA just sweltered through a very warm night, after a day of extreme heat where some regional areas reached nearly 48C.\",\n",
    "            \"region\": \"SA\",\n",
    "            \"time\": \"2019-01-03 17:57:00\",\n",
    "            \"rationality\": \"Extreme weather conditions, particularly the intense heat, will lead to higher electricity consumption in the short term as residents and businesses increase the use of air conditioning and cooling systems to manage temperatures.\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"A sudden cold snap in Victoria leads to a spike in electric heating usage.\",\n",
    "            \"region\": \"VIC\",\n",
    "            \"time\": \"2019-01-04 05:22:00\",\n",
    "            \"rationality\": \"Short-term electricity load spikes are often caused by unexpected weather events that drive up heating or cooling demand.\"\n",
    "        }\n",
    "    ],\n",
    "    \"Real-Time Direct Effect on Today's Load Consumption\": [\n",
    "        {\n",
    "            \"news\": \"An unseasonal downpour has wreaked havoc on Perth’s electricity network this morning.\",\n",
    "            \"region\": \"WA\",\n",
    "            \"time\": \"2019-01-03 10:11:00\",\n",
    "            \"rationality\": \"The sudden weather event causing disruptions to the electricity network can have an immediate impact on load consumption due to power outages, infrastructure damage, or emergency response measures.\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Lightning strike at a major substation causes widespread outages in Sydney.\",\n",
    "            \"region\": \"NSW\",\n",
    "            \"time\": \"2019-01-03 19:45:00\",\n",
    "            \"rationality\": \"Direct effects on load consumption include sudden drops in power supply, triggering emergency measures to restore stability in the network.\"\n",
    "        }\n",
    "    ]}\"\"\"\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "selected_news = pd.DataFrame(columns=['time', 'news'])\n",
    "file_path = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_news/news_processed_data_2019-2022.json\"\n",
    "        \n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "news_df = pd.DataFrame(data)\n",
    "news_df['publication_time'] = pd.to_datetime(news_df['publication_time'])\n",
    "\n",
    "dates_range= pd.date_range(start=f\"2019-01-01\", end=f\"2021-01-01\")\n",
    "\n",
    "for date in dates_range:\n",
    "    formatted_date = date.strftime('%Y-%m-%d')\n",
    "    news_before,news_after=fetch_news(date, 1, news_df)\n",
    "    if (news_before == \" No news found before the prediction date.\") & (news_after == \" No news found on the prediction date.\"):\n",
    "        continue\n",
    "    prompt1 = f\"The prediction date is {formatted_date}.\"\n",
    "    prompt3 = f\"The news happened before and on the prediction include:{news_before+news_after}\"\n",
    "\n",
    "    prompt = initial_reasoning + prompt1 + prompt2 + prompt3 + format_output2\n",
    "    response = gpt_reselect_news(prompt)\n",
    "    response = response[response.find(\"{\"):response.rfind(\"}\") + 1].replace(\"\\n\", \"\")\n",
    "    print(response)\n",
    "\n",
    "    try:\n",
    "        response_json = json.loads(response)\n",
    "        print(\"The response is in JSON format.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"The response is not in JSON format.\")\n",
    "\n",
    "    news_string = response #response\n",
    "    df_extended = pd.DataFrame({'time': [formatted_date], 'news': [news_string]})\n",
    "    selected_news = pd.concat([selected_news, df_extended], ignore_index=True)\n",
    "\n",
    "\n",
    "    csv_file_path = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AU_load_news_dataframe_2019-2020_iteration_0.csv'\n",
    "    selected_news.to_csv(csv_file_path, index=False, encoding='utf-8')  # index=False 表示不保存行索引\n",
    "\n",
    "print(selected_news.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(csv_file_path)\n",
    "justify_news_format_final(news_csv,'/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AU_load_merge_file_final_iteration_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_data_file = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/combined_weather_data.csv\"\n",
    "news_data_file = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AU_load_merge_file_final_iteration_0.csv\"\n",
    "ts_file = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF-2019-2023.csv'\n",
    "save_file = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_output_list_v4_3_2019-2020_iteration_0.json'\n",
    "\n",
    "result_list = parse_news_TS_final(weather_data_file,news_data_file,ts_file,save_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(save_file, 'r', encoding='utf-8') as file: \n",
    "    result_list = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file_path = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_output_list_v4_3_2019-2020_iteration_0.json'\n",
    "train_save_file = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_train_data_v4_3_2019-2020_iteration_0.json'\n",
    "val_save_file = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_validation_data_v4_3_2019-2020_iteration_0.json'\n",
    "val_num = 100\n",
    "\n",
    "train_validation_split(json_file_path,train_save_file,val_save_file,val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_a_new_train(\n",
    "    'AU-LF-test-iteration-0',\n",
    "    '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_train_data_v4_3_2019-2020_iteration_0.json',\n",
    "    resume_from_checkpoint='/root/autodl-tmp/results/AU-LF-test-iteration-0/checkpoint-500',\n",
    "    result_saving_dir='/root/autodl-tmp/results/',\n",
    "    learning_rate='1e-4',\n",
    "    epoch=4,\n",
    "    save_steps=250,\n",
    "    prompter_name='ts_test',\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=6,\n",
    "    lora_r=8,\n",
    "    lora_alpha=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_evaluation(\n",
    "    '/root/autodl-tmp/results/AU-LF-test-iteration-0/checkpoint-1000',\n",
    "    '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_validation_data_v4_3_2019-2020_iteration_0.json',\n",
    "    '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_test_result_v4_3_2019-2020_iteration_0.json',\n",
    "    prompter_name='ts_test',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actuals_file = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_validation_data_v4_3_2019-2020_iteration_0.json\"\n",
    "predictions_file = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_test_result_v4_3_2019-2020_iteration_0.json\"\n",
    "plot_comparision(predictions_file,actuals_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Logic Upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "predictions_file = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_test_result_v4_3_2019-2020_iteration_0.json'\n",
    "actuals_file = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AULF_validation_data_v4_3_2019-2020_iteration_0.json'\n",
    "all_news_file = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_news/news_processed_data_2019-2022.json\"\n",
    "\n",
    "# Load the initial content for selecting news logic\n",
    "# If it's after the second training or later, select the previous news logic\n",
    "with open('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/select_news_logic_iteration_0.txt', 'r') as file:\n",
    "    selection_news_logic_latest = file.read()\n",
    "    print(selection_news_logic_latest)\n",
    "    \n",
    "# Load the initial format for selecting news logic\n",
    "with open('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/select_news_logic_iteration_format.txt', 'r') as file:\n",
    "    selection_news_logic_format = file.read()\n",
    "    print(selection_news_logic_format)\n",
    "\n",
    "with open(actuals_file, 'r', encoding='utf-8') as f:\n",
    "        actuals_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()  # Start time for the entire process\n",
    "\n",
    "all_response = []\n",
    "\n",
    "for i in range(len(actuals_data)):\n",
    "    iteration_start = time.time()\n",
    "    \n",
    "    actual,errors,background,historical_time,predictions_time,selected_news,all_news=validation_with_evaluation_agent (i,predictions_file, actuals_file,all_news_file)\n",
    "    response = gpt_chain_of_thoughts(background, selected_news, all_news, predictions_time, actual, errors,selection_news_logic_format,selection_news_logic_latest)\n",
    "    if response == \"'str' object has no attribute 'get'\":\n",
    "        print(response)\n",
    "        iteration_end = time.time()  # End time for the current iteration\n",
    "        print(f\"Iteration {i} completed in {iteration_end - iteration_start:.2f} seconds\")\n",
    "        continue\n",
    "    else:\n",
    "        print(response) \n",
    "        selection_news_logic_latest = response.replace(\"**\", \" \").replace(\"###\", \" \")\n",
    "        all_response.append(response)\n",
    "        iteration_end = time.time()  # End time for the current iteration\n",
    "        print(f\"Iteration {i} completed in {iteration_end - iteration_start:.2f} seconds\")\n",
    "\n",
    "total_time = time.time() - start_time  # Total time after all iterations are completed\n",
    "print(f\"All iterations completed in {total_time:.2f} seconds\")\n",
    "\n",
    "#saving the updated logic\n",
    "all_response_array = np.array(all_response)\n",
    "np.save('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/adjusted_selection_logic_iteration_0.npy', all_response_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = #enter your api base \n",
    "openai.api_key = #enter your api key \n",
    "selection_news_logic_all = np.load('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/adjusted_selection_logic_iteration_0.npy')\n",
    "\n",
    "file_path = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/select_news_logic_iteration_0.txt'\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    initial_logic = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Improve and polish this paragraph to reduce repeated content and summarize the news selection logic \n",
    "that affects the electricity load consumption:{selection_news_logic_all.tolist()}'''\n",
    "\n",
    "prompt2 = f'''\n",
    "According to the given updated logic, please directly rephrase the current prediction\n",
    "logic and output the adjusted new logic. This is the current prediction logic that you need to adjust\n",
    "and improve: {initial_logic}'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo-2024-04-09\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant analyzing electricity load predictions.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt1+prompt2}\n",
    "            ]\n",
    "        )\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"] )\n",
    "new_logic = response[\"choices\"][0][\"message\"][\"content\"] \n",
    "with open('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/select_news_logic_iteration_1.txt', \"w\", encoding='utf-8') as file:\n",
    "    file.write(response[\"choices\"][0][\"message\"][\"content\"].replace(\"**\",\"\").replace(\"\\n\",\"\").replace(\"###\",\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Select News in the Next Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/select_news_logic_iteration_1.txt', 'r') as file:\n",
    "    initial_reasoning = file.read()\n",
    "    print(initial_reasoning)\n",
    "    \n",
    "raw_news_file_path = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_news/news_processed_data_2019-2022.json\"\n",
    "csv_file_path = '/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AU_load_news_dataframe_2019-2020_iteration_1.csv'\n",
    "reselect_news_procedure(raw_news_file_path,csv_file_path,initial_reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AU_load_news_dataframe_2019-2020_iteration_1.csv\")\n",
    "save_file = \"/root/llama2-lora-fine-tuning/ipython_notebook_1004/Data_all/AU_load/AU_load_merged_file_final_iteration_1.csv\"\n",
    "justify_news_format_final(news_csv,save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
